{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Importamos las librerías necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "guBKTtm8kJuA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "I8wt5rgqowe0"
      },
      "source": [
        "### Iniciamos con la lectura de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "TWQfy1RXovjd"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel(\"real_estate_data.xlsx\", index_col = [0])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dMIaoLaIo_7f"
      },
      "source": [
        "#### Formateo de los nombres de las columnas para remover espacios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "vJF2BefMo8uj"
      },
      "outputs": [],
      "source": [
        "def format_cols_spaces(columns):\n",
        "  return {key:key.replace(\" \",\"_\") for key in columns}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Funcion para estandarizar la data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {},
      "outputs": [],
      "source": [
        "def standardize_data(data):\n",
        "    new_data = data.copy()\n",
        "    for col in new_data.columns:\n",
        "        new_data[col] = (new_data[col] - new_data[col].mean()) / new_data[col].std()\n",
        "    return new_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "S0NJbWwQo-uK"
      },
      "outputs": [],
      "source": [
        "columns_replace = format_cols_spaces(df.columns)\n",
        "df = df.rename(columns = columns_replace)\n",
        "df_train = df.loc[0:315].copy()\n",
        "df_test = df.loc[316:].copy()\n",
        "df_train_norm = standardize_data(df_train)\n",
        "df_test_norm = standardize_data(df_test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "r5jwiIfwp3u1"
      },
      "source": [
        "### Creamos la clase NeuralNetwork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "id": "DutzLmDmp9Li"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork:\n",
        "  def __init__(self, activation, eps, learning_rate, epochs):\n",
        "\n",
        "    #Inicializacion de pesos\n",
        "    self.W1 = np.random.random((5,6))\n",
        "    self.b1 = np.random.random((5,1))\n",
        "\n",
        "    self.W2 = np.random.random((1,5))\n",
        "    self.b2 = np.random.random((1,1))\n",
        "\n",
        "    #Inicializacion de hiperparametros\n",
        "    self.eps = eps\n",
        "    self.learning_rate = learning_rate\n",
        "    self.epochs = epochs\n",
        "    self.activation = self.sigmoid if activation == \"sigmoid\" else self.relu\n",
        "\n",
        "  def relu(self,X):\n",
        "    return np.maximum(0,X)\n",
        "  \n",
        "  def sigmoid(self,X):\n",
        "    return 1/(1+np.exp(-X))\n",
        "\n",
        "  def forward(self, X):\n",
        "    zi = self.W1@X + self.b1\n",
        "    zi = self.activation(zi)\n",
        "    y_hat = self.W2@zi + self.b2\n",
        "    return y_hat \n",
        "  \n",
        "  def funcion_objetivo(self, X, y):\n",
        "    return 0.5*np.mean((self.forward(X).T - y)**2)\n",
        "  \n",
        "  def numerical_gradient(self, X, y):\n",
        "      # Calcular el gradiente numérico\n",
        "      eps = self.eps\n",
        "      grads = {}\n",
        "      for param_name in [\"W1\", \"b1\", \"W2\", \"b2\"]:\n",
        "          param = getattr(self, param_name)\n",
        "          loss_mat = np.zeros_like(param)\n",
        "          ## For loop para W1\n",
        "          for i in range(param.shape[0]):\n",
        "            for j in range(param.shape[1]):\n",
        "                original_value = param[i, j]\n",
        "                param[i, j] = original_value + eps\n",
        "                grad_plus = self.funcion_objetivo(X, y)\n",
        "                param[i, j] = original_value - eps\n",
        "                grad_minus = self.funcion_objetivo(X, y)\n",
        "                param[i, j] = original_value\n",
        "                loss_mat[i, j] = (grad_plus - grad_minus) / (2 * eps)\n",
        "          grads[param_name] = loss_mat\n",
        "      return grads\n",
        "  \n",
        "#funcion fit y loop de entrenamiento\n",
        "  def fit(self, X, y):\n",
        "    learning_rate = self.learning_rate\n",
        "    epochs = self.epochs\n",
        "    print(\"Entrenando...\")\n",
        "    # Inicializar historial de pérdidas\n",
        "    loss_history = []\n",
        "\n",
        "    # Ciclo de entrenamiento\n",
        "    for epoch in range(epochs):\n",
        "        # Calculamos los gradientes\n",
        "        grads = self.numerical_gradient(X, y)\n",
        "\n",
        "        # Actualizamos los pesos y bias\n",
        "        for param_name in [\"W1\", \"b1\", \"W2\", \"b2\"]:\n",
        "            param = getattr(self, param_name)\n",
        "            grad = grads[param_name]\n",
        "            param -= learning_rate * grad\n",
        "        loss = self.funcion_objetivo(X, y)\n",
        "        loss_history.append(loss)\n",
        "    return loss_history[-1]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "id": "jaq7Cukgs-Z9"
      },
      "outputs": [],
      "source": [
        "df_train_X = df_train.drop(['Y_house_price_of_unit_area'], axis = 1)\n",
        "df_train_y = df_train[['Y_house_price_of_unit_area']]\n",
        "\n",
        "df_train_X_norm = df_train_norm.drop(['Y_house_price_of_unit_area'], axis = 1)\n",
        "df_train_y_norm = df_train_norm[['Y_house_price_of_unit_area']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "Hs2ueMUItwC9"
      },
      "outputs": [],
      "source": [
        "train_X_values = df_train_X.values.T\n",
        "train_y_values = df_train_y.values\n",
        "\n",
        "train_X_norm_values = df_train_X_norm.values.T\n",
        "# train_y_norm_values = df_train_y_norm.values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(315, 1)"
            ]
          },
          "execution_count": 196,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_y_values.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "id": "3LoBW2uEveDC"
      },
      "outputs": [],
      "source": [
        "for eps in range(2,5):\n",
        "    for learning_rate in range(2,5):\n",
        "        for epochs in range(2,5):\n",
        "            for activation in [\"sigmoid\", \"relu\"]:\n",
        "                nn = NeuralNetwork(activation, 10**(-eps), 10**(-learning_rate), 10**(epochs))\n",
        "                nn.fit(train_X_values, train_y_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test_X = df_test.drop(['Y_house_price_of_unit_area'], axis = 1)\n",
        "df_test_y = df_test[['Y_house_price_of_unit_area']]\n",
        "\n",
        "df_test_X_norm = df_test_norm.drop(['Y_house_price_of_unit_area'], axis = 1)\n",
        "df_test_y_norm = df_test_norm[['Y_house_price_of_unit_area']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {},
      "outputs": [],
      "source": [
        "preds = neural_1.forward(df_test_X_norm.values.T)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 99)"
            ]
          },
          "execution_count": 150,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "66.00471078521562"
            ]
          },
          "execution_count": 151,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mse = np.mean((preds.T - df_test_y.values)**2)\n",
        "mse"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
