{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Importamos las librerías necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "guBKTtm8kJuA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "I8wt5rgqowe0"
      },
      "source": [
        "### Iniciamos con la lectura de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "TWQfy1RXovjd"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel(\"real_estate_data.xlsx\", index_col = [0])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dMIaoLaIo_7f"
      },
      "source": [
        "#### Formateo de los nombres de las columnas para remover espacios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "vJF2BefMo8uj"
      },
      "outputs": [],
      "source": [
        "def format_cols_spaces(columns):\n",
        "  return {key:key.replace(\" \",\"_\") for key in columns}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Funcion para estandarizar la data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def standardize_data(data):\n",
        "    new_data = data.copy()\n",
        "    for col in new_data.columns:\n",
        "        new_data[col] = (new_data[col] - new_data[col].mean()) / new_data[col].std()\n",
        "    return new_data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Formateamos la data y normalizamos los datos de train y test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "S0NJbWwQo-uK"
      },
      "outputs": [],
      "source": [
        "columns_replace = format_cols_spaces(df.columns)\n",
        "df = df.rename(columns = columns_replace)\n",
        "df_train = df.loc[0:315].copy()\n",
        "df_test = df.loc[316:].copy()\n",
        "mean_std = df_train.describe().loc[[\"mean\",\"std\"]]\n",
        "df_train_norm = standardize_data(df_train)\n",
        "df_test_norm = df_test.apply(lambda x: (x - mean_std.loc[\"mean\"]) / mean_std.loc[\"std\"], axis = 1)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "r5jwiIfwp3u1"
      },
      "source": [
        "### Creamos la clase NeuralNetwork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "DutzLmDmp9Li"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork:\n",
        "  def __init__(self, activation, eps, learning_rate, epochs, for_train):\n",
        "\n",
        "    #Inicializacion de pesos\n",
        "    self.W1 = np.random.random((5,6))\n",
        "    self.b1 = np.random.random((5,1))\n",
        "\n",
        "    self.W2 = np.random.random((1,5))\n",
        "    self.b2 = np.random.random((1,1))\n",
        "\n",
        "    #Para ver si devolvemos la loss history o solo loss_history[-1]\n",
        "    self.for_train = for_train\n",
        "\n",
        "    #Inicializacion de hiperparametros\n",
        "    self.eps = eps\n",
        "    self.learning_rate = learning_rate\n",
        "    self.epochs = epochs\n",
        "    self.activation = self.sigmoid if activation == \"sigmoid\" else self.relu\n",
        "\n",
        "  def relu(self,X):\n",
        "    return np.maximum(0,X)\n",
        "  \n",
        "  def sigmoid(self,X):\n",
        "    return 1/(1+np.exp(-X))\n",
        "\n",
        "  def forward(self, X):\n",
        "    zi = self.W1@X + self.b1\n",
        "    zi = self.activation(zi)\n",
        "    y_hat = self.W2@zi + self.b2\n",
        "    return y_hat \n",
        "  \n",
        "  def funcion_objetivo(self, X, y):\n",
        "    return 0.5*np.mean((self.forward(X).T - y)**2)\n",
        "  \n",
        "  def numerical_gradient(self, X, y):\n",
        "      # Calcular el gradiente numérico por cada parámetro\n",
        "      eps = self.eps\n",
        "      grads = {}\n",
        "      for param_name in [\"W1\", \"b1\", \"W2\", \"b2\"]:\n",
        "          param = getattr(self, param_name)\n",
        "          loss_mat = np.zeros_like(param)\n",
        "          ## For loop para W1\n",
        "          for i in range(param.shape[0]):\n",
        "            for j in range(param.shape[1]):\n",
        "                original_value = param[i, j]\n",
        "                param[i, j] = original_value + eps\n",
        "                grad_plus = self.funcion_objetivo(X, y)\n",
        "                param[i, j] = original_value - eps\n",
        "                grad_minus = self.funcion_objetivo(X, y)\n",
        "                param[i, j] = original_value\n",
        "                loss_mat[i, j] = (grad_plus - grad_minus) / (2 * eps)\n",
        "          grads[param_name] = loss_mat\n",
        "      return grads\n",
        "  \n",
        "#funcion fit y loop de entrenamiento\n",
        "  def fit(self, X, y):\n",
        "    learning_rate = self.learning_rate\n",
        "    epochs = self.epochs\n",
        "    # Inicializar historial de pérdidas\n",
        "    loss_history = []\n",
        "\n",
        "    # Ciclo de entrenamiento\n",
        "    for epoch in range(epochs):\n",
        "        # Calculamos los gradientes\n",
        "        grads = self.numerical_gradient(X, y)\n",
        "\n",
        "        # Actualizamos los pesos y bias\n",
        "        for param_name in [\"W1\", \"b1\", \"W2\", \"b2\"]:\n",
        "            param = getattr(self, param_name)\n",
        "            grad = grads[param_name]\n",
        "            param -= learning_rate * grad\n",
        "        loss = self.funcion_objetivo(X, y)\n",
        "        loss_history.append(loss)\n",
        "    if self.for_train:\n",
        "       return loss_history[-1]\n",
        "    else:\n",
        "       return loss_history\n",
        "       \n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Separamos ambos datasets en X e y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "jaq7Cukgs-Z9"
      },
      "outputs": [],
      "source": [
        "df_train_X = df_train.drop(['Y_house_price_of_unit_area'], axis = 1)\n",
        "df_train_y = df_train[['Y_house_price_of_unit_area']]\n",
        "\n",
        "df_train_X_norm = df_train_norm.drop(['Y_house_price_of_unit_area'], axis = 1)\n",
        "df_train_y_norm = df_train_norm[['Y_house_price_of_unit_area']]\n",
        "\n",
        "df_test_X = df_test.drop(['Y_house_price_of_unit_area'], axis = 1)\n",
        "df_test_y = df_test[['Y_house_price_of_unit_area']]\n",
        "\n",
        "df_test_X_norm = df_test_norm.drop(['Y_house_price_of_unit_area'], axis = 1)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Nos guardamos los valores del Dataset sin las columnas y trasponemos para que queden compatibles las dimensiones con los pesos y biases.\n",
        "- Aclaración:\n",
        "No normalizamos los y, dado que esos valores queremos mantenerlos.\n",
        "Lo que normalizamos son los X de train para que ningún feature quede\n",
        "dominante solo por una diferencia de escala."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "Hs2ueMUItwC9"
      },
      "outputs": [],
      "source": [
        "train_X_values = df_train_X.values.T\n",
        "train_y_values = df_train_y.values\n",
        "\n",
        "train_X_norm_values = df_train_X_norm.values.T\n",
        "test_X_norm_values = df_test_X_norm.values.T\n",
        "\n",
        "test_y_values = df_test_y.values\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "neural_1 = NeuralNetwork(\"sigmoid\", 0.0001, 0.001, 1000,False)\n",
        "loss_1 =   neural_1.fit(train_X_norm_values, train_y_values)\n",
        "\n",
        "epochs = np.arange(1,1001)\n",
        "plt.plot(epochs, loss_1)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss vs Epochs\")\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Inicializamos el ciclo de entrenamiento.\n",
        "- Rangos:\n",
        "- Epsilon (1e-4, 1e-2)\n",
        "- Learning Rate (1e-4, 1e-2)\n",
        "- Epochs (10^2,10^5)\n",
        "- Funciones de activación (ReLu, Sigmoide)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "3LoBW2uEveDC"
      },
      "outputs": [],
      "source": [
        "def train_model(eps_range, learning_rate_range, epochs_range):\n",
        "    training_list = []\n",
        "    for eps in range(eps_range[0], eps_range[1]):\n",
        "        for learning_rate in range(learning_rate_range[0], learning_rate_range[1]):\n",
        "            for epochs in range(epochs_range[0], epochs_range[1]):\n",
        "                for activation in [\"sigmoid\", \"relu\"]:\n",
        "                    neural1 = NeuralNetwork(activation, 10**(-eps), 10**(-learning_rate), 10**(epochs), True)\n",
        "                    loss = neural1.fit(train_X_norm_values, train_y_values)\n",
        "                    training_list.append([eps, learning_rate, epochs, activation, loss])\n",
        "    return training_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_list_1 = train_model((2,5), (2,5), (2,5))\n",
        "training_list_2 = train_model((2,5), (1,5), (2,5))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Guardamos las iteraciones en un dataframe para poder analizarlas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_loss_1 = pd.DataFrame(training_list_1, columns = [\"eps\", \"learning_rate\", \"epochs\", \"activation\", \"loss\"])\n",
        "data_loss_2 = pd.DataFrame(training_list_2, columns = [\"eps\", \"learning_rate\", \"epochs\", \"activation\", \"loss\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_loss_1 = data_loss_1.sort_values(by = \"loss\", ascending = True)\n",
        "data_loss_1['learning_rate'] = data_loss_1['learning_rate'].apply(lambda x: 10**(-x))\n",
        "data_loss_1['eps'] = data_loss_1['eps'].apply(lambda x: 10**(-x))\n",
        "data_loss_1['epochs'] = data_loss_1['epochs'].apply(lambda x: 10**(x))\n",
        "data_loss_1.reset_index(inplace = True, drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_loss_2 = data_loss_2.sort_values(by = \"loss\", ascending = True)\n",
        "data_loss_2['learning_rate'] = data_loss_2['learning_rate'].apply(lambda x: 10**(-x))\n",
        "data_loss_2['eps'] = data_loss_2['eps'].apply(lambda x: 10**(-x))\n",
        "data_loss_2['epochs'] = data_loss_2['epochs'].apply(lambda x: 10**(x))\n",
        "data_loss_2.reset_index(inplace = True, drop = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eps</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>epochs</th>\n",
              "      <th>activation</th>\n",
              "      <th>loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>10000</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>24.793836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>10000</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>24.870604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>10000</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>25.493315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>10000</td>\n",
              "      <td>relu</td>\n",
              "      <td>26.957123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>10000</td>\n",
              "      <td>relu</td>\n",
              "      <td>27.968787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>10000</td>\n",
              "      <td>relu</td>\n",
              "      <td>28.494270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>10000</td>\n",
              "      <td>relu</td>\n",
              "      <td>29.181692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>1000</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>29.638118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>1000</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>29.792508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>10000</td>\n",
              "      <td>relu</td>\n",
              "      <td>30.047732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>10000</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>30.171611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>1000</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>30.248486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>1000</td>\n",
              "      <td>relu</td>\n",
              "      <td>30.321734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>10000</td>\n",
              "      <td>relu</td>\n",
              "      <td>30.630888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>10000</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>30.818821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>1000</td>\n",
              "      <td>relu</td>\n",
              "      <td>30.980668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>10000</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>31.100808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>1000</td>\n",
              "      <td>relu</td>\n",
              "      <td>31.291547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>100</td>\n",
              "      <td>relu</td>\n",
              "      <td>32.738606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>1000</td>\n",
              "      <td>relu</td>\n",
              "      <td>33.203129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>1000</td>\n",
              "      <td>relu</td>\n",
              "      <td>33.434131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>100</td>\n",
              "      <td>relu</td>\n",
              "      <td>33.688224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10000</td>\n",
              "      <td>relu</td>\n",
              "      <td>33.945038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>1000</td>\n",
              "      <td>relu</td>\n",
              "      <td>34.118072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10000</td>\n",
              "      <td>relu</td>\n",
              "      <td>34.123621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10000</td>\n",
              "      <td>relu</td>\n",
              "      <td>34.284144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>100</td>\n",
              "      <td>relu</td>\n",
              "      <td>34.385057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10000</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>45.273480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>1000</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>45.604111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>100</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>45.740622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>100</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>45.742080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10000</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>46.195339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>1000</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>46.257970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>1000</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>46.367756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>10000</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>46.996083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0100</td>\n",
              "      <td>100</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>47.621525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>1000</td>\n",
              "      <td>relu</td>\n",
              "      <td>58.159312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>100</td>\n",
              "      <td>relu</td>\n",
              "      <td>59.568118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>100</td>\n",
              "      <td>relu</td>\n",
              "      <td>61.346890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>1000</td>\n",
              "      <td>relu</td>\n",
              "      <td>83.253641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>1000</td>\n",
              "      <td>relu</td>\n",
              "      <td>84.600116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>100</td>\n",
              "      <td>relu</td>\n",
              "      <td>96.396788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>100</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>369.600454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>1000</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>377.873177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>100</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>384.569786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>1000</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>394.320579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0010</td>\n",
              "      <td>100</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>397.282647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>1000</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>423.513687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100</td>\n",
              "      <td>relu</td>\n",
              "      <td>577.260815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100</td>\n",
              "      <td>relu</td>\n",
              "      <td>603.677954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100</td>\n",
              "      <td>relu</td>\n",
              "      <td>629.158122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>697.547981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>726.321709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>742.291990</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       eps  learning_rate  epochs activation        loss\n",
              "0   0.0100         0.0100   10000    sigmoid   24.793836\n",
              "1   0.0001         0.0100   10000    sigmoid   24.870604\n",
              "2   0.0010         0.0100   10000    sigmoid   25.493315\n",
              "3   0.0100         0.0100   10000       relu   26.957123\n",
              "4   0.0010         0.0100   10000       relu   27.968787\n",
              "5   0.0001         0.0100   10000       relu   28.494270\n",
              "6   0.0001         0.0010   10000       relu   29.181692\n",
              "7   0.0100         0.0100    1000    sigmoid   29.638118\n",
              "8   0.0001         0.0100    1000    sigmoid   29.792508\n",
              "9   0.0010         0.0010   10000       relu   30.047732\n",
              "10  0.0010         0.0010   10000    sigmoid   30.171611\n",
              "11  0.0010         0.0100    1000    sigmoid   30.248486\n",
              "12  0.0001         0.0100    1000       relu   30.321734\n",
              "13  0.0100         0.0010   10000       relu   30.630888\n",
              "14  0.0001         0.0010   10000    sigmoid   30.818821\n",
              "15  0.0010         0.0100    1000       relu   30.980668\n",
              "16  0.0100         0.0010   10000    sigmoid   31.100808\n",
              "17  0.0100         0.0100    1000       relu   31.291547\n",
              "18  0.0100         0.0100     100       relu   32.738606\n",
              "19  0.0100         0.0010    1000       relu   33.203129\n",
              "20  0.0001         0.0010    1000       relu   33.434131\n",
              "21  0.0001         0.0100     100       relu   33.688224\n",
              "22  0.0100         0.0001   10000       relu   33.945038\n",
              "23  0.0010         0.0010    1000       relu   34.118072\n",
              "24  0.0001         0.0001   10000       relu   34.123621\n",
              "25  0.0010         0.0001   10000       relu   34.284144\n",
              "26  0.0010         0.0100     100       relu   34.385057\n",
              "27  0.0001         0.0001   10000    sigmoid   45.273480\n",
              "28  0.0100         0.0010    1000    sigmoid   45.604111\n",
              "29  0.0001         0.0100     100    sigmoid   45.740622\n",
              "30  0.0010         0.0100     100    sigmoid   45.742080\n",
              "31  0.0100         0.0001   10000    sigmoid   46.195339\n",
              "32  0.0001         0.0010    1000    sigmoid   46.257970\n",
              "33  0.0010         0.0010    1000    sigmoid   46.367756\n",
              "34  0.0010         0.0001   10000    sigmoid   46.996083\n",
              "35  0.0100         0.0100     100    sigmoid   47.621525\n",
              "36  0.0100         0.0001    1000       relu   58.159312\n",
              "37  0.0001         0.0010     100       relu   59.568118\n",
              "38  0.0100         0.0010     100       relu   61.346890\n",
              "39  0.0010         0.0001    1000       relu   83.253641\n",
              "40  0.0001         0.0001    1000       relu   84.600116\n",
              "41  0.0010         0.0010     100       relu   96.396788\n",
              "42  0.0001         0.0010     100    sigmoid  369.600454\n",
              "43  0.0010         0.0001    1000    sigmoid  377.873177\n",
              "44  0.0100         0.0010     100    sigmoid  384.569786\n",
              "45  0.0100         0.0001    1000    sigmoid  394.320579\n",
              "46  0.0010         0.0010     100    sigmoid  397.282647\n",
              "47  0.0001         0.0001    1000    sigmoid  423.513687\n",
              "48  0.0010         0.0001     100       relu  577.260815\n",
              "49  0.0100         0.0001     100       relu  603.677954\n",
              "50  0.0001         0.0001     100       relu  629.158122\n",
              "51  0.0010         0.0001     100    sigmoid  697.547981\n",
              "52  0.0001         0.0001     100    sigmoid  726.321709\n",
              "53  0.0100         0.0001     100    sigmoid  742.291990"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_loss_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eps</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>epochs</th>\n",
              "      <th>activation</th>\n",
              "      <th>loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.10</td>\n",
              "      <td>10000</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>2.242778e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.10</td>\n",
              "      <td>10000</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>2.285404e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.01</td>\n",
              "      <td>10000</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>2.418299e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.01</td>\n",
              "      <td>10000</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>2.426358e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.10</td>\n",
              "      <td>1000</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>2.437575e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.10</td>\n",
              "      <td>100</td>\n",
              "      <td>relu</td>\n",
              "      <td>2.329101e+82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.10</td>\n",
              "      <td>10000</td>\n",
              "      <td>relu</td>\n",
              "      <td>5.064376e+83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.10</td>\n",
              "      <td>1000</td>\n",
              "      <td>relu</td>\n",
              "      <td>3.725068e+107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.10</td>\n",
              "      <td>1000</td>\n",
              "      <td>relu</td>\n",
              "      <td>5.532938e+113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>0.0010</td>\n",
              "      <td>0.10</td>\n",
              "      <td>100</td>\n",
              "      <td>relu</td>\n",
              "      <td>2.614512e+121</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>72 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       eps  learning_rate  epochs activation           loss\n",
              "0   0.0100           0.10   10000    sigmoid   2.242778e+02\n",
              "1   0.0001           0.10   10000    sigmoid   2.285404e+02\n",
              "2   0.0010           0.01   10000    sigmoid   2.418299e+02\n",
              "3   0.0100           0.01   10000    sigmoid   2.426358e+02\n",
              "4   0.0001           0.10    1000    sigmoid   2.437575e+02\n",
              "..     ...            ...     ...        ...            ...\n",
              "67  0.0001           0.10     100       relu   2.329101e+82\n",
              "68  0.0010           0.10   10000       relu   5.064376e+83\n",
              "69  0.0100           0.10    1000       relu  3.725068e+107\n",
              "70  0.0010           0.10    1000       relu  5.532938e+113\n",
              "71  0.0010           0.10     100       relu  2.614512e+121\n",
              "\n",
              "[72 rows x 5 columns]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_loss_2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Como podemos ver en data_loss_2 el minimo valor encontrado es mejor que en data_loss_1. Esto sucede porque data_loss_2 incluye un learing rate que es 0.1 el cual data_loss_1 no incluye. Este learning rate es un poco mas \"extremo\", luego con funciones de activacion como ReLu los valores no convergen. Sin embargo el valor minimo de la loss con sigmoide es menor que el de data_loss_1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "neural_best = NeuralNetwork(\"sigmoid\", 0.01, 0.1, 10000, True)\n",
        "loss_best = neural_best.fit(train_X_norm_values, train_y_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "22.420517534905958"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss_best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "51.45103153117248\n"
          ]
        }
      ],
      "source": [
        "preds = neural_best.forward(test_X_norm_values)\n",
        "preds = preds.T\n",
        "preds\n",
        "mse = np.mean((preds - test_y_values)**2)\n",
        "print(mse)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
